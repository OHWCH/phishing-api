from flask import Flask, request, jsonify
import os
import stat
import pickle
import numpy as np
import requests
import uuid
from pydub import AudioSegment
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import speech_recognition as sr

# âœ… [1] ffmpeg ì‹¤í–‰ ê¶Œí•œ ìë™ ë¶€ì—¬
ffmpeg_path = "bin/ffmpeg"
if os.path.exists(ffmpeg_path):
    st = os.stat(ffmpeg_path)
    if not bool(st.st_mode & stat.S_IXUSR):  # ì‚¬ìš©ì ì‹¤í–‰ê¶Œí•œ ì—†ìœ¼ë©´
        os.chmod(ffmpeg_path, st.st_mode | stat.S_IXUSR)

# âœ… [2] ffmpeg ê²½ë¡œ ì„¤ì •
AudioSegment.converter = "./bin/ffmpeg"

# ---------------------- ì„¤ì • ----------------------
MODEL_PATH = "phishing_model.h5"
TOKENIZER_PATH = "tokenizer.pkl"
UPLOAD_PATH = "temp.wav"
MAX_LEN = 100
THRESHOLD = 0.5
LLM_API_KEY = os.environ.get("LLM_API_KEY")

# ---------------------- Flask ì„œë²„ ì´ˆê¸°í™” ----------------------
app = Flask(__name__)

# ---------------------- í´ë˜ìŠ¤: ëª¨ë¸ ë¡œë” ----------------------
class ModelLoader:
    def __init__(self, model_path, tokenizer_path):
        print("ğŸ” ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...")
        self.model = load_model(model_path)
        with open(tokenizer_path, "rb") as f:
            self.tokenizer = pickle.load(f)
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# ---------------------- í´ë˜ìŠ¤: ìŒì„± ì¸ì‹ê¸° ----------------------
class STTProcessor:
    def __init__(self):
        self.recognizer = sr.Recognizer()

    def transcribe(self, audio_path):
        try:
            with sr.AudioFile(audio_path) as source:
                audio_data = self.recognizer.record(source)
                text = self.recognizer.recognize_google(audio_data, language="ko-KR")
                return text
        except sr.UnknownValueError:
            return None
        except sr.RequestError as e:
            raise Exception(f"Google STT ì˜¤ë¥˜: {str(e)}")

# ---------------------- í´ë˜ìŠ¤: ìœ„í—˜ë„ ì˜ˆì¸¡ê¸° ----------------------
class RiskAnalyzer:
    def __init__(self, model_loader):
        self.model = model_loader.model
        self.tokenizer = model_loader.tokenizer

    def predict(self, text):
        seq = self.tokenizer.texts_to_sequences([text])
        padded = pad_sequences(seq, maxlen=MAX_LEN)
        score = float(self.model.predict(padded)[0][0])
        return score

# ---------------------- í´ë˜ìŠ¤: LLM ë¶„ì„ê¸° ----------------------
class LLMAnalyzer:
    def __init__(self, api_key):
        self.api_key = api_key

    def analyze(self, text):
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": "tngtech/deepseek-r1t-chimera:free",
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "ë‹¹ì‹ ì€ ë³´ì´ìŠ¤í”¼ì‹± íƒì§€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                        "ì•„ë˜ ë¬¸ì¥ì´ ë³´ì´ìŠ¤í”¼ì‹±ì¸ì§€ íŒë‹¨í•´ ì£¼ì„¸ìš”."
                        "ë³´ì´ìŠ¤í”¼ì‹±ì˜ ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤\n"
                        "- ê¸ˆì „ ìš”êµ¬(ì†¡ê¸ˆ, ì…ê¸ˆ, ëŒ€ì¶œ, íˆ¬ì ê¶Œìœ  ë“±)\n"
                        "- ê¸´ë°•í•œ ìƒí™© ì¡°ì„±(ìë…€ ì‚¬ê³ , ê²€ì°°Â·ê²½ì°° ì‚¬ì¹­, ê³„ì¢Œ ì •ì§€, ê°œì¸ì •ë³´ ë…¸ì¶œ ë“±)\n"
                        "- ì „í™”ë‚˜ ë¬¸ì ë“±ìœ¼ë¡œ ê°œì¸ì •ë³´, ê¸ˆìœµì •ë³´ë¥¼ ìš”êµ¬í•˜ê±°ë‚˜ ì¡°ì‘ëœ ë§í¬ í´ë¦­ì„ ìœ ë„\n"
                        "- ë§íˆ¬ë‚˜ ë‹¨ì–´ì—ì„œ ë¶ˆì•ˆ, í˜‘ë°•, íšŒìœ , ê¸‰ë°•í•¨ì´ ëŠê»´ì§ˆ ê²½ìš°\n"
                        "- ê°ì •ì ìœ¼ë¡œ ì••ë°•í•˜ë©° ì£„ì±…ê°ì„ ìœ ë„í•˜ëŠ” ê²½ìš°\n"
                        "- ê¸ˆì „ì„ ë¹Œë ¤ë‹¬ë¼ëŠ” ìš”êµ¬ë¥¼ í†µí•´ ìƒëŒ€ë°©ì„ ê³µë²”ìœ¼ë¡œ ë§Œë“¤ë ¤ëŠ” ê²½ìš°ê°€ ìˆëŠ”ê²½ìš°\n"
                        "í•´ë‹¹ ë¬¸ì¥ì´ ìœ„ **ê¸°ì¤€ì— ë¶€í•©í•˜ë©´ â€œë³´ì´ìŠ¤í”¼ì‹±ì…ë‹ˆë‹¤â€**, **ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ â€œì •ìƒ ëŒ€í™”ì…ë‹ˆë‹¤â€** ë¼ê³  **ë”± í•œ ë¬¸ì¥ë§Œ ì¶œë ¥**í•˜ì‹­ì‹œì˜¤."
                    )
                },
                {
                    "role": "user",
                    "content": text
                }
            ]
        }

        try:
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=payload
            )
            if response.status_code == 200:
                result = response.json()["choices"][0]["message"]["content"].strip()
                return result
            else:
                return "LLM ë¶„ì„ ì˜¤ë¥˜"
        except Exception as e:
            return f"LLM ì—°ê²° ì‹¤íŒ¨: {str(e)}"

# ---------------------- ì´ˆê¸°í™” ----------------------
model_loader = ModelLoader(MODEL_PATH, TOKENIZER_PATH)
stt = STTProcessor()
analyzer = RiskAnalyzer(model_loader)
llm = LLMAnalyzer(LLM_API_KEY)

# ---------------------- API ë¼ìš°í„° ----------------------
@app.route("/analyze", methods=["POST"])
def analyze_audio():
    if "audio" not in request.files:
        return jsonify({"error": "audio íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    # ğŸ”§ 1. ì„ì‹œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    temp_id = uuid.uuid4().hex
    temp_3gp_path = f"{temp_id}.3gp"
    temp_wav_path = f"{temp_id}.wav"

    # ğŸ”§ 2. 3gp íŒŒì¼ ì €ì¥
    audio = request.files["audio"]
    audio.save(temp_3gp_path)

    try:
        # ğŸ”§ 3. 3gp â†’ wav ë³€í™˜
        audio_segment = AudioSegment.from_file(temp_3gp_path, format="3gp")
        audio_segment.export(temp_wav_path, format="wav")
        
        # 4. STT ì²˜ë¦¬
        text = stt.transcribe(temp_wav_path)
        if text is None:
            return jsonify({"error": "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}), 400

        # 5. ëª¨ë¸ ì˜ˆì¸¡
        score = analyzer.predict(text)
        result = "ë³´ì´ìŠ¤í”¼ì‹± ì˜ì‹¬ë¨" if score > THRESHOLD else "ì •ìƒ ëŒ€í™”"

        # 6. LLM ë¶„ì„
        llm_result = None
        if score > THRESHOLD:
            llm_result = llm.analyze(text)

            # ê²°ê³¼ ê²€ì¦
            if llm_result not in ["ë³´ì´ìŠ¤í”¼ì‹±ì…ë‹ˆë‹¤", "ì •ìƒ ëŒ€í™”ì…ë‹ˆë‹¤"]:
                llm_result = "LLM ë¶„ì„ ì˜¤ë¥˜ ë˜ëŠ” íŒë‹¨ ë¶ˆê°€"

        return jsonify({
            "recognized_text": text,
            "risk_score": score,
            "model_result": result,
            "llm_result": llm_result or "LLM ë¶„ì„ ìƒëµë¨"
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

    finally:
        # ğŸ”§ 7. ì„ì‹œ íŒŒì¼ ì‚­ì œ
        for f in [temp_3gp_path, temp_wav_path]:
            if os.path.exists(f):
                os.remove(f)

# ---------------------- ì„œë²„ ì‹¤í–‰ ----------------------
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
